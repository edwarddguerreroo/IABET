"""
ğŸ” DEBUG COMPLETO - ASSISTS FEATURE ENGINEER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Script de debugging exhaustivo para el feature engineer de AST.
Verifica:
- Carga de datos y Ã­ndices
- GeneraciÃ³n de features por grupo
- Porcentaje de NaN en cada feature
- Orden de ejecuciÃ³n
- Integridad de datos
- PropagaciÃ³n correcta de NaN (sin fallbacks)

Autor: Sistema de Debug Automatizado
Fecha: 2025-01-24
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Agregar el directorio raÃ­z al path
sys.path.insert(0, str(Path(__file__).parent))

from app.architectures.basketball.src.preprocessing.data_loader import NBADataLoader
from app.architectures.basketball.src.models.players.ast.features_ast import AssistsFeatureEngineer

def print_section(title: str, char: str = "â•"):
    """Imprime una secciÃ³n con formato"""
    print(f"\n{char * 80}")
    print(f"  {title}")
    print(f"{char * 80}\n")

def print_subsection(title: str):
    """Imprime una subsecciÃ³n con formato"""
    print(f"\n{'â”€' * 80}")
    print(f"  {title}")
    print(f"{'â”€' * 80}")

def analyze_feature_quality(df: pd.DataFrame, feature_name: str) -> dict:
    """Analiza la calidad de una feature"""
    if feature_name not in df.columns:
        return {
            'exists': False,
            'total_count': 0,
            'valid_count': 0,
            'nan_count': 0,
            'nan_percentage': 100.0,
            'zero_count': 0,
            'zero_percentage': 0.0,
            'mean': np.nan,
            'std': np.nan,
            'min': np.nan,
            'max': np.nan
        }
    
    series = df[feature_name]
    total = len(series)
    valid = series.notna().sum()
    nan_count = series.isna().sum()
    zero_count = (series == 0).sum()
    
    return {
        'exists': True,
        'total_count': total,
        'valid_count': valid,
        'nan_count': nan_count,
        'nan_percentage': (nan_count / total * 100) if total > 0 else 0,
        'zero_count': zero_count,
        'zero_percentage': (zero_count / total * 100) if total > 0 else 0,
        'mean': series.mean() if valid > 0 else np.nan,
        'std': series.std() if valid > 0 else np.nan,
        'min': series.min() if valid > 0 else np.nan,
        'max': series.max() if valid > 0 else np.nan
    }

def print_feature_stats(stats: dict, feature_name: str):
    """Imprime estadÃ­sticas de una feature"""
    if not stats['exists']:
        print(f"âŒ {feature_name}: NO EXISTE")
        return
    
    # Determinar el emoji segÃºn el porcentaje de NaN
    if stats['nan_percentage'] < 10:
        emoji = "âœ…"
    elif stats['nan_percentage'] < 30:
        emoji = "âš ï¸"
    else:
        emoji = "ğŸ”´"
    
    print(f"{emoji} {feature_name}:")
    print(f"   Valid: {stats['valid_count']:,}/{stats['total_count']:,} ({100-stats['nan_percentage']:.1f}%)")
    print(f"   NaN: {stats['nan_count']:,} ({stats['nan_percentage']:.1f}%)")
    if stats['zero_count'] > 0:
        print(f"   Zeros: {stats['zero_count']:,} ({stats['zero_percentage']:.1f}%)")
    if pd.notna(stats['mean']):
        print(f"   Stats: mean={stats['mean']:.3f}, std={stats['std']:.3f}, min={stats['min']:.3f}, max={stats['max']:.3f}")

def main():
    print_section("ğŸš€ INICIO DEL DEBUG - ASSISTS FEATURE ENGINEER", "â•")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. CARGA DE DATOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("1ï¸âƒ£ CARGA DE DATOS", "â•")
    
    try:
        print("ğŸ“‚ Cargando datos desde NBADataLoader...")
        data_loader = NBADataLoader()
        
        # Cargar datos principales (retorna tupla)
        result = data_loader.load_data(use_quarters=False, force_reload=False)
        if isinstance(result, tuple):
            df_players, df_teams, _, _ = result
        else:
            df_players = result
            df_teams = None
        
        print(f"âœ… Datos de jugadores cargados: {len(df_players):,} filas")
        if df_teams is not None:
            print(f"âœ… Datos de equipos cargados: {len(df_teams):,} filas")
        else:
            print(f"âš ï¸  Datos de equipos no disponibles")
        
        # Cargar datos de quarters
        result_quarters = data_loader.load_data(use_quarters=True, force_reload=False)
        if isinstance(result_quarters, tuple):
            df_quarters, _, _, _ = result_quarters
        else:
            df_quarters = result_quarters
        
        print(f"âœ… Datos de quarters cargados: {len(df_quarters):,} filas")
        
        # InformaciÃ³n bÃ¡sica
        print_subsection("ğŸ“Š INFORMACIÃ“N BÃSICA DEL DATASET")
        print(f"Shape: {df_players.shape}")
        print(f"Columnas: {len(df_players.columns)}")
        print(f"Jugadores Ãºnicos: {df_players['player'].nunique()}")
        print(f"Temporadas: {df_players['Season'].nunique() if 'Season' in df_players.columns else 'N/A'}")
        
        # Verificar columna de asistencias
        if 'assists' in df_players.columns:
            print(f"\nâœ… Columna 'assists' encontrada")
            print(f"   Total asistencias: {df_players['assists'].sum():,.0f}")
            print(f"   Promedio por juego: {df_players['assists'].mean():.2f}")
            print(f"   MÃ¡ximo en un juego: {df_players['assists'].max():.0f}")
        else:
            print("âŒ ERROR: Columna 'assists' no encontrada!")
            return
        
        # Verificar Ã­ndices
        print_subsection("ğŸ” VERIFICACIÃ“N DE ÃNDICES")
        print(f"Tipo de Ã­ndice: {type(df_players.index)}")
        print(f"Nombre del Ã­ndice: {df_players.index.name}")
        print(f"Ãndices Ãºnicos: {df_players.index.is_unique}")
        print(f"Ãndices monotÃ³nicos: {df_players.index.is_monotonic_increasing}")
        
        if isinstance(df_players.index, pd.MultiIndex):
            print(f"Niveles del MultiIndex: {df_players.index.names}")
            print(f"Ejemplo de Ã­ndice: {df_players.index[0]}")
        else:
            print(f"Primeros 5 Ã­ndices: {df_players.index[:5].tolist()}")
        
        # Crear subset para testing (Ãºltimas 1000 filas para velocidad)
        print_subsection("ğŸ¯ CREACIÃ“N DE SUBSET DE PRUEBA")
        df_test = df_players.tail(1000).copy()
        print(f"âœ… Subset creado: {len(df_test):,} filas")
        print(f"   Jugadores en subset: {df_test['player'].nunique()}")
        print(f"   Asistencias promedio: {df_test['assists'].mean():.2f}")
        
    except Exception as e:
        print(f"âŒ ERROR en carga de datos: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. INICIALIZACIÃ“N DEL FEATURE ENGINEER
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("2ï¸âƒ£ INICIALIZACIÃ“N DEL FEATURE ENGINEER", "â•")
    
    try:
        print("ğŸ”§ Inicializando AssistsFeatureEngineer...")
        feature_engineer = AssistsFeatureEngineer(
            teams_df=df_teams,
            players_df=df_players,
            players_quarters_df=df_quarters
        )
        print("âœ… Feature Engineer inicializado correctamente")
        
        # Verificar que los DataFrames se pasaron correctamente
        print_subsection("ğŸ” VERIFICACIÃ“N DE DATAFRAMES")
        print(f"teams_df: {'âœ… Asignado' if feature_engineer.teams_df is not None else 'âŒ None'}")
        print(f"players_df: {'âœ… Asignado' if feature_engineer.players_df is not None else 'âŒ None'}")
        print(f"players_quarters_df: {'âœ… Asignado' if feature_engineer.players_quarters_df is not None else 'âŒ None'}")
        
    except Exception as e:
        print(f"âŒ ERROR en inicializaciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. GENERACIÃ“N DE FEATURES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("3ï¸âƒ£ GENERACIÃ“N DE FEATURES", "â•")
    
    try:
        print("ğŸ¨ Generando todas las features...")
        print("â±ï¸  Esto puede tomar unos segundos...\n")
        
        # Generar features (retorna DataFrame transformado)
        df_features = feature_engineer.generate_all_features(df_test)
        
        print(f"âœ… Features generadas exitosamente!")
        print(f"   Shape original: {df_test.shape}")
        print(f"   Shape con features: {df_features.shape}")
        print(f"   Features agregadas: {df_features.shape[1] - df_test.shape[1]}")
        
        # Verificar Ã­ndices despuÃ©s de feature engineering
        print_subsection("ğŸ” VERIFICACIÃ“N DE ÃNDICES POST-FEATURES")
        print(f"Tipo de Ã­ndice: {type(df_features.index)}")
        print(f"Ãndices Ãºnicos: {df_features.index.is_unique}")
        print(f"Longitud del Ã­ndice: {len(df_features.index)}")
        
        if len(df_features) != len(df_test):
            print(f"âš ï¸  ADVERTENCIA: Cambio en nÃºmero de filas!")
            print(f"   Antes: {len(df_test)}, DespuÃ©s: {len(df_features)}")
        
    except Exception as e:
        print(f"âŒ ERROR en generaciÃ³n de features: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. ANÃLISIS DETALLADO POR GRUPO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("4ï¸âƒ£ ANÃLISIS DETALLADO POR GRUPO DE FEATURES", "â•")
    
    # Definir grupos de features segÃºn la arquitectura
    feature_groups = {
        "GRUPO 0: Dataset Features (~5%)": [
            'ast_to_ratio_enhanced',
            'fast_break_playmaking',
            'second_chance_creation',
            'true_shooting_support',
            'efficiency_rating_synergy',
            'defensive_assist_impact'
        ],
        "GRUPO 1: Evolutionary Features (51.98% - DOMINANTE)": [
            'evolutionary_selection_pressure',
            'evolutionary_dominance_index',
            'player_adaptability_score',
            'evolutionary_momentum_predictor',
            'genetic_algorithm_predictor'
        ],
        "GRUPO 2: Positioning Features (6.49%)": [
            'minutes_based_ast_predictor',
            'minutes_expected'
        ],
        "GRUPO 3: Context/Efficiency Features (3.46%)": [
            'home_away_ast_factor',
            'player_offensive_load_pct_l10'
        ],
        "GRUPO 4: Assist Range Features (~2%)": [
            'ast_explosion_potential',
            'extreme_ast_game_freq'
        ],
        "GRUPO 5A: Basic Historical Features": [
            'ast_avg_3g',
            'ast_avg_10g',
            'ast_avg_20g',
            'ast_season_avg',
            'ast_hybrid_predictor',
            'position_index',
            'adaptive_volatility_predictor',
            'evolutionary_fitness',
            'evolutionary_mutation_rate',
            'dynamic_range_predictor',
            'ultra_efficiency_predictor',
            'high_volume_efficiency'
        ],
        "GRUPO 5B: Dataset-Based Features": [
            'assist_momentum_acceleration',
            'efficiency_game_score_impact',
            'fouls_drawn_playmaking',
            'second_chance_playmaking',
            'fast_break_playmaking_enhanced',
            'defensive_rating_impact',
            'offensive_rating_synergy',
            'blocked_attempts_playmaking',
            'plus_minus_momentum'
        ],
        "GRUPO 5C: Elite & Explosive Features": [
            'elite_player_scaling',
            'explosive_game_potential',
            'high_volume_game_indicator',
            'star_player_momentum'
        ],
        "GRUPO 5D: Quarter-Based Features": [
            'quarter_explosive_detection',
            'quarter_consistency_pattern',
            'quarter_momentum_acceleration',
            'elite_quarter_performance',
            'quarter_based_game_projection'
        ],
        "GRUPO 6: Opponent Context Features (~2.8%)": [
            'real_opponent_def_rating',
            'opp_pts_allowed',
            'opponent_adaptation_score'
        ]
    }
    
    # Analizar cada grupo
    all_stats = {}
    problematic_features = []
    
    for group_name, features in feature_groups.items():
        print_subsection(f"ğŸ“Š {group_name}")
        
        for feature in features:
            stats = analyze_feature_quality(df_features, feature)
            all_stats[feature] = stats
            print_feature_stats(stats, feature)
            
            # Identificar features problemÃ¡ticas (>50% NaN)
            if stats['exists'] and stats['nan_percentage'] > 50:
                problematic_features.append({
                    'feature': feature,
                    'nan_pct': stats['nan_percentage'],
                    'group': group_name
                })
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. RESUMEN DE CALIDAD
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("5ï¸âƒ£ RESUMEN DE CALIDAD DE FEATURES", "â•")
    
    # Contar features por calidad
    excellent = sum(1 for s in all_stats.values() if s['exists'] and s['nan_percentage'] < 10)
    good = sum(1 for s in all_stats.values() if s['exists'] and 10 <= s['nan_percentage'] < 30)
    warning = sum(1 for s in all_stats.values() if s['exists'] and 30 <= s['nan_percentage'] < 50)
    poor = sum(1 for s in all_stats.values() if s['exists'] and s['nan_percentage'] >= 50)
    missing = sum(1 for s in all_stats.values() if not s['exists'])
    
    print(f"ğŸ“Š DISTRIBUCIÃ“N DE CALIDAD:")
    print(f"   âœ… Excelente (<10% NaN): {excellent} features")
    print(f"   âš ï¸  Bueno (10-30% NaN): {good} features")
    print(f"   ğŸŸ¡ Advertencia (30-50% NaN): {warning} features")
    print(f"   ğŸ”´ Pobre (>50% NaN): {poor} features")
    print(f"   âŒ No existe: {missing} features")
    print(f"   ğŸ“ˆ TOTAL: {len(all_stats)} features analizadas")
    
    # Features problemÃ¡ticas
    if problematic_features:
        print_subsection("âš ï¸  FEATURES CON PROBLEMAS")
        for pf in sorted(problematic_features, key=lambda x: x['nan_pct'], reverse=True):
            print(f"ğŸ”´ {pf['feature']}: {pf['nan_pct']:.1f}% NaN")
            print(f"   Grupo: {pf['group']}")
            
            # Sugerencias de soluciÃ³n
            if 'quarter' in pf['feature'].lower():
                print(f"   ğŸ’¡ Causa: Depende de players_quarters_df")
                print(f"   ğŸ’¡ SoluciÃ³n: Verificar disponibilidad de datos por cuarto")
            elif 'opp' in pf['feature'].lower() or 'opponent' in pf['feature'].lower():
                print(f"   ğŸ’¡ Causa: Depende de datos del oponente")
                print(f"   ğŸ’¡ SoluciÃ³n: Verificar columna 'Opp' y teams_df")
            else:
                print(f"   ğŸ’¡ SoluciÃ³n: Verificar disponibilidad de columnas base")
    else:
        print("âœ… Â¡No hay features con >50% NaN!")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. VERIFICACIÃ“N DE FALLBACKS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("6ï¸âƒ£ VERIFICACIÃ“N DE FALLBACKS (DEBE SER 0)", "â•")
    
    print("ğŸ” Buscando valores sospechosos que podrÃ­an indicar fallbacks...")
    
    # Valores comunes de fallback
    fallback_values = {
        0: "Cero (comÃºn fallback)",
        1.0: "Uno (comÃºn para ratios)",
        3.0: "Tres (promedio de asistencias)",
        105.0: "105 (defensive rating)",
        110.0: "110 (offensive rating)",
        20.0: "20 (minutos)",
        0.5: "0.5 (ratio genÃ©rico)"
    }
    
    suspicious_features = []
    
    for feature, stats in all_stats.items():
        if not stats['exists']:
            continue
        
        series = df_features[feature]
        
        # Verificar valores exactos sospechosos
        for value, description in fallback_values.items():
            exact_count = (series == value).sum()
            if exact_count > len(series) * 0.5:  # MÃ¡s del 50% con el mismo valor
                suspicious_features.append({
                    'feature': feature,
                    'value': value,
                    'count': exact_count,
                    'percentage': (exact_count / len(series) * 100),
                    'description': description
                })
    
    if suspicious_features:
        print("âš ï¸  FEATURES CON VALORES SOSPECHOSOS:")
        for sf in suspicious_features:
            print(f"ğŸŸ¡ {sf['feature']}:")
            print(f"   Valor: {sf['value']} ({sf['description']})")
            print(f"   Frecuencia: {sf['count']:,}/{len(df_features):,} ({sf['percentage']:.1f}%)")
            print(f"   âš ï¸  Posible fallback hardcoded!")
    else:
        print("âœ… Â¡No se detectaron fallbacks sospechosos!")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. VERIFICACIÃ“N DE ÃNDICES Y ALINEACIÃ“N
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("7ï¸âƒ£ VERIFICACIÃ“N DE ÃNDICES Y ALINEACIÃ“N", "â•")
    
    print("ğŸ” Verificando alineaciÃ³n de Ã­ndices...")
    
    # Verificar que los Ã­ndices se mantienen
    if df_test.index.equals(df_features.index):
        print("âœ… Ãndices perfectamente alineados")
    else:
        print("âš ï¸  ADVERTENCIA: Ãndices no coinciden!")
        print(f"   Ãndices originales: {len(df_test.index)}")
        print(f"   Ãndices finales: {len(df_features.index)}")
    
    # Verificar que 'assists' (target) NO estÃ¡ presente (diseÃ±o anti-leakage)
    if 'assists' in df_features.columns:
        print("âŒ ERROR: Columna target 'assists' presente (RIESGO DE LEAKAGE!)")
    else:
        print("âœ… Columna target 'assists' NO presente (diseÃ±o anti-leakage correcto)")
        print("   âœ… Feature Engineer retorna SOLO features, sin target")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. EJEMPLOS DE DATOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("8ï¸âƒ£ EJEMPLOS DE DATOS GENERADOS", "â•")
    
    # Seleccionar algunas features clave para mostrar
    key_features = [
        'ast_avg_10g',
        'evolutionary_selection_pressure',
        'minutes_based_ast_predictor',
        'home_away_ast_factor',
        'real_opponent_def_rating',
        'quarter_explosive_detection'
    ]
    
    available_features = [f for f in key_features if f in df_features.columns]
    
    if available_features:
        print("ğŸ“‹ MUESTRA DE DATOS (Ãºltimas 10 filas):")
        # Nota: df_features YA NO contiene 'player' porque retorna SOLO features
        print(df_features[available_features].tail(10).to_string())
        print("\nâš ï¸  NOTA: 'player' NO estÃ¡ en df_features (por diseÃ±o anti-leakage)")
    else:
        print("âš ï¸  No hay features clave disponibles para mostrar")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. REPORTE FINAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("9ï¸âƒ£ REPORTE FINAL", "â•")
    
    print("ğŸ“Š RESUMEN EJECUTIVO:")
    print(f"   â€¢ Dataset: {len(df_features):,} filas, {df_features.shape[1]} columnas")
    print(f"   â€¢ Features generadas: {df_features.shape[1] - df_test.shape[1]}")
    print(f"   â€¢ Features analizadas: {len(all_stats)}")
    print(f"   â€¢ Features excelentes: {excellent} (âœ…)")
    print(f"   â€¢ Features con problemas: {poor} (ğŸ”´)")
    print(f"   â€¢ Features sospechosas: {len(suspicious_features)} (ğŸŸ¡)")
    
    print("\nğŸ¯ ESTADO GENERAL:")
    if poor == 0 and len(suspicious_features) == 0:
        print("   âœ… EXCELENTE - Todas las features estÃ¡n correctas")
    elif poor <= 2 and len(suspicious_features) <= 2:
        print("   âš ï¸  BUENO - Algunas features necesitan atenciÃ³n")
    else:
        print("   ğŸ”´ REQUIERE ATENCIÃ“N - MÃºltiples features con problemas")
    
    print("\nğŸ’¡ RECOMENDACIONES:")
    if poor > 0:
        print(f"   1. Revisar {poor} features con >50% NaN")
    if len(suspicious_features) > 0:
        print(f"   2. Verificar {len(suspicious_features)} features con posibles fallbacks")
    if poor == 0 and len(suspicious_features) == 0:
        print("   âœ… No hay recomendaciones - Sistema funcionando correctamente")
    
    print_section("âœ… DEBUG COMPLETADO", "â•")

if __name__ == "__main__":
    main()

